---
title: "Deep Learning"
author: "MA"
date: "May 7, 2018"
output: github_document
---

This project attempts to clusify handwritten digits from the MNIST dataset.

Load the package *keras*.
```{r,echo=TRUE}
#install.packages("keras")
library(keras)
#install_keras()
```

Get the digits data ready and look at the structure of the data set
```{r, echo=TRUE}
mnist <- dataset_mnist()
#look at the data class
class(mnist)
length(mnist)
names(mnist) #it shows minist is a list with length of two, train and test
#extract the training and test data respectively 
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
class(x_train)
dim(x_train)
length(x_train)# 47040000 in total
```

Reshape each image into a single vector with size 28*28 and rescale the values between 0 and 1
```{r,echo=TRUE}
dim(x_train) <- c(nrow(x_train), 784)
dim(x_test) <- c(nrow(x_test), 784)
x_train <- x_train / 255
x_test <- x_test / 255
```

Convert the y values into binary class matrices to build the model.
```{r,echo=TRUE}
y_train[1:3]
class(y_train)
dim(y_train)#vector
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
class(y_train)
length(y_train)
length(mnist$train$y) #should be length(y_train)/10
```

Build the model using keras package.
```{r,echo=TRUE}
model <- keras_model_sequential() 
model#initial model
model %>% 
  layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = "softmax")

model

#compile the model with appropriate loss function, optimizer, and metrics:
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("accuracy")
)

```

Train the model with data using fit function.
```{r,echo=TRUE}
history <- model %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)
plot(history)
```


Evaluate the modelâ€™s performance on the test data and predict the future.
```{r,echo=TRUE}
model %>% evaluate(x_test, y_test,verbose = 0)
predicts<-model %>% predict_classes(x_test)
library(caret)
confusionMatrix(predicts,mnist$test$y)
```






